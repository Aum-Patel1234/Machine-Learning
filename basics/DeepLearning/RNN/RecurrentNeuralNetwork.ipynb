{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfff836",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "An RNN, or Recurrent Neural Network, is a type of artificial neural network designed for processing sequences of data. Unlike traditional feedforward neural networks, which process data in fixed-size input vectors, RNNs are capable of handling input sequences of variable length, making them well-suited for tasks involving time series data, natural language processing, and other sequential data types.\n",
    "\n",
    "The key feature of RNNs is their ability to maintain a hidden state that captures information from previous time steps in the sequence. This hidden state is updated as new inputs are processed, allowing the network to capture temporal dependencies and context within the sequence.\n",
    "\n",
    "Here's a simplified explanation of how an RNN works:\n",
    "\n",
    "- Initialization: At the start of processing a sequence, the RNN initializes its hidden state to a fixed size vector, typically containing zeros.\n",
    "\n",
    "- Sequential Processing: The RNN processes the input sequence one element at a time, such as one word in a sentence or one data point in a time series. At each time step, it takes the current input and combines it with the previous hidden state to produce an output and update the hidden state.\n",
    "\n",
    "- Recurrent Connections: The recurrent connections in the RNN allow information to flow from one time step to the next, enabling the network to capture dependencies and patterns within the sequence.\n",
    "\n",
    "RNNs have been used in various applications, including natural language processing (e.g., language modeling and machine translation), speech recognition, time series analysis, and more. However, they have some limitations, such as difficulty in capturing long-range dependencies, which has led to the development of more advanced recurrent architectures like Long Short-Term Memory (LSTM) networks and Gated Recurrent Unit (GRU) networks, which are designed to address some of these issues.\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1400/1*xs2EgGPGlpWrSW4zUANYXA.png)\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1194/1*B0q2ZLsUUw31eEImeVf3PQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33160007",
   "metadata": {},
   "source": [
    "As we can see, the calculations at each time step consider the context of the previous time steps in the form of the hidden state. Being able to use this contextual information from previous inputs is the key essence to RNNs’ success in sequential problems.\n",
    "\n",
    "While it may seem that a different RNN cell is being used at each time step in the graphics, the underlying principle of Recurrent Neural Networks is that the RNN cell is actually the exact same one and reused throughout.\n",
    "\n",
    "\n",
    "## Processing RNN Outputs?\n",
    "\n",
    "You might be wondering, which portion of the RNN do I extract my output from? This really depends on what your use case is. For example, if you’re using the RNN for a classification task, you’ll only need one final output after passing in all the input - a vector representing the class probability scores. In another case, if you’re doing text generation based on the previous character/word, you’ll need an output at every single time step.\n",
    "\n",
    "![alt text](https://blog.floydhub.com/content/images/2019/04/karpathy.jpeg)\n",
    "\n",
    "This is where RNNs are really flexible and can adapt to your needs. As seen in the image above, your input and output size can come in different forms, yet they can still be fed into and extracted from the RNN model.\n",
    "\n",
    "![alt text](https://blog.floydhub.com/content/images/2019/04/Slide6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd2a6f",
   "metadata": {},
   "source": [
    "For the case where you’ll only need a single output from the whole process, getting that output can be fairly straightforward as you can easily take the output produced by the last RNN cell in the sequence. As this final output has already undergone calculations through all the previous cells, the context of all the previous inputs has been captured. This means that the final result is indeed dependent on all the previous computations and inputs.\n",
    "\n",
    "![alt text](https://blog.floydhub.com/content/images/2019/04/Slide7.jpg)\n",
    "\n",
    "For the second case where you’ll need output information from the intermediate time steps, this information can be taken from the hidden state produced at each step as shown in the figure above. The output produced can also be fed back into the model at the next time step if necessary.\n",
    "\n",
    "Of course, the type of output that you can obtain from an RNN model is not limited to just these two cases. There are other methods such as Sequence-To-Sequence translation where the output is only produced in a sequence after all the input has been passed through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ef790",
   "metadata": {},
   "source": [
    "## Inner Workings\n",
    "\n",
    "Now that we have a basic understanding and a bird's eye view of how RNNs work, let's explore some basic computations that the RNN’s cells have to do to produce the hidden states and outputs.\n",
    "\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <msub>\n",
    "    <mtext>hidden</mtext>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <mtext>F</mtext>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mtext>hidden</mtext>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mtext>input</mtext>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>\n",
    "\n",
    "\n",
    "In the first step, a hidden state will usually be seeded as a matrix of zeros, so that it can be fed into the RNN cell together with the first input in the sequence. In the simplest RNNs, the hidden state and the input data will be multiplied with weight matrices initialized via a scheme such as Xavier or Kaiming. The result of these multiplications will then be passed through an activation function(such as a tanh function) to introduce non-linearity.\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <msub>\n",
    "    <mtext>hidden</mtext>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <mtext>tanh</mtext>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mtext>weight</mtext>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>h</mi>\n",
    "      <mi>i</mi>\n",
    "      <mi>d</mi>\n",
    "      <mi>d</mi>\n",
    "      <mi>e</mi>\n",
    "      <mi>n</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>&#x2217;<!-- ∗ --></mo>\n",
    "  <msub>\n",
    "    <mtext>hidden</mtext>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "      <mo>&#x2212;<!-- − --></mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>+</mo>\n",
    "  <msub>\n",
    "    <mtext>weight</mtext>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>i</mi>\n",
    "      <mi>n</mi>\n",
    "      <mi>p</mi>\n",
    "      <mi>u</mi>\n",
    "      <mi>t</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>&#x2217;<!-- ∗ --></mo>\n",
    "  <msub>\n",
    "    <mtext>input</mtext>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>t</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>\n",
    "\n",
    "\n",
    "Additionally, if we require an output at the end of each time step we can pass the hidden state that we just produced through a linear layer or just multiply it by another weight matrix to obtain the desired shape of the result.\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <msub>\n",
    "    <mtext>output</mtext>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "  <mo>=</mo>\n",
    "  <msub>\n",
    "    <mtext>weight</mtext>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mi>o</mi>\n",
    "      <mi>u</mi>\n",
    "      <mi>t</mi>\n",
    "      <mi>p</mi>\n",
    "      <mi>u</mi>\n",
    "      <mi>t</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>&#x2217;<!-- ∗ --></mo>\n",
    "  <msub>\n",
    "    <mtext>hidden</mtext>\n",
    "    <mi>t</mi>\n",
    "  </msub>\n",
    "</math>\n",
    "\n",
    "\n",
    "The hidden state that we just produced will then be fed back into the RNN cell together with the next input and this process continues until we run out of input or the model is programmed to stop producing outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5472e",
   "metadata": {},
   "source": [
    "During training, for each piece of training data we’ll have a corresponding ground-truth label, or simply put a“correct answer” that we want the model to output. Of course, for the first few times that we pass the input data through the model, we won’t obtain outputs that are equal to these correct answers. However, after receiving these outputs, what we’ll do during training is that we’ll calculate the loss of that process, which measures how far off the model’s output is from the correct answer. Using this loss, we can calculate the gradient of the loss function for back-propagation.\n",
    "\n",
    "With the gradient that we just obtained, we can update the weights in the model accordingly so that future computations with the input data will produce more accurate results. The weight here refers to the weight matrices that are multiplied with the input data and hidden states during the forward pass. This entire process of calculating the gradients and updating the weights is called back-propagation. Combined with the forward pass, back-propagation is looped over and again, allowing the model to become more accurate with its outputs each time as the weight matrices values are modified to pick out the patterns of the data.\n",
    "\n",
    "Although it may look as if each RNN cell is using a different weight as shown in the graphics, all of the weights are actually the same as that RNN cell is essentially being re-used throughout the process. Therefore, only the input data and hidden state carried forward are unique at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225af71",
   "metadata": {},
   "source": [
    "## Code:\n",
    "\n",
    "We will be building and training a basic character-level Recurrent Neural Network (RNN) to classify words. A character-level RNN reads words as a series of characters - outputting a prediction and “hidden state” at each step, feeding its previous hidden state into each next step. We take the final prediction to be the output, i.e. which class the word belongs to.\n",
    "\n",
    "Specifically, we’ll train on a few thousand surnames from 18 languages of origin, and predict which language a name is from based on the spelling:\n",
    "\n",
    "\n",
    "Dataset Link: https://download.pytorch.org/tutorial/data.zip\n",
    "\n",
    "Included in the data/names directory are 18 text files named as [Language].txt. Each file contains a bunch of names, one name per line, mostly romanized (but we still need to convert from Unicode to ASCII).\n",
    "\n",
    "We’ll end up with a dictionary of lists of names per language, {language: [names ...]}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5280e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/ravikumarpande/miniconda3/envs/cme-env/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ravikumarpande/miniconda3/envs/cme-env/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eee57f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1152891b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from string import ascii_letters\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb733eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035e994e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'china'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'china.txt'.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c34dbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 {'Czech': tensor([0]), 'German': tensor([1]), 'Japanese': tensor([2]), 'Chinese': tensor([3]), 'Vietnamese': tensor([4]), 'French': tensor([5]), 'Irish': tensor([6]), 'Spanish': tensor([7]), 'Greek': tensor([8]), 'Italian': tensor([9]), 'Portuguese': tensor([10]), 'Scottish': tensor([11]), 'Dutch': tensor([12]), 'Korean': tensor([13]), 'Polish': tensor([14])}\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/names\"\n",
    "\n",
    "lang2label = {\n",
    "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long)\n",
    "    for i, file_name in enumerate(os.listdir(data_dir))\n",
    "}\n",
    "num_langs = len(lang2label)\n",
    "print(num_langs, lang2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572fdaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Czech': tensor([0]), 'German': tensor([1]), 'Japanese': tensor([2]), 'Chinese': tensor([3]), 'Vietnamese': tensor([4]), 'French': tensor([5]), 'Irish': tensor([6]), 'Spanish': tensor([7]), 'Greek': tensor([8]), 'Italian': tensor([9]), 'Portuguese': tensor([10]), 'Scottish': tensor([11]), 'Dutch': tensor([12]), 'Korean': tensor([13]), 'Polish': tensor([14])}\n"
     ]
    }
   ],
   "source": [
    "print(lang2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58bd730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Czech.txt', 'data/names/German.txt', 'data/names/Japanese.txt', 'data/names/Chinese.txt', 'data/names/Vietnamese.txt', 'data/names/French.txt', 'data/names/Irish.txt', 'data/names/Spanish.txt', 'data/names/Greek.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Scottish.txt', 'data/names/Dutch.txt', 'data/names/Korean.txt', 'data/names/Polish.txt']\n"
     ]
    }
   ],
   "source": [
    "def findFiles(path):\n",
    "    return glob.glob(path)\n",
    "\n",
    "\n",
    "print(findFiles(\"data/names/*.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2a5f3",
   "metadata": {},
   "source": [
    "\n",
    "Python Unidecode is a library that converts Unicode strings to ASCII strings. This can be useful for a variety of reasons, such as:\n",
    "\n",
    "To make text compatible with older systems that do not support Unicode.\n",
    "To create filenames that are compatible with all operating systems.\n",
    "To improve the performance of applications that need to process large amounts of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad0ad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slusarski'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(\"Ślusàrski\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060ec282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "096177a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51}\n"
     ]
    }
   ],
   "source": [
    "# character level encoding\n",
    "\n",
    "char2idx = {letter: i for i, letter in enumerate(ascii_letters)}\n",
    "num_letters = len(char2idx)\n",
    "print(num_letters)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0544d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nword => w -> [0 ,0, ..., 1, 0, 0, 0] -> o\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "word => w -> [0 ,0, ..., 1, 0, 0, 0] -> o\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ab68d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'a'\n",
    "#'meena' -> 5 x 1 x 52\n",
    "vector = torch.zeros(1, 52)\n",
    "vector[0][char2idx['A']] = 1\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c611c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, num_letters)\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i][0][char2idx[char]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c8850d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.]],\n",
       "\n",
       "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tensor('ravi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09b74f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Czech': tensor([0]),\n",
       " 'German': tensor([1]),\n",
       " 'Japanese': tensor([2]),\n",
       " 'Chinese': tensor([3]),\n",
       " 'Vietnamese': tensor([4]),\n",
       " 'French': tensor([5]),\n",
       " 'Irish': tensor([6]),\n",
       " 'Spanish': tensor([7]),\n",
       " 'Greek': tensor([8]),\n",
       " 'Italian': tensor([9]),\n",
       " 'Portuguese': tensor([10]),\n",
       " 'Scottish': tensor([11]),\n",
       " 'Dutch': tensor([12]),\n",
       " 'Korean': tensor([13]),\n",
       " 'Polish': tensor([14])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05e6ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_names = []\n",
    "target_langs = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, file)) as f:\n",
    "        lang = file.split(\".\")[0]\n",
    "        names = [unidecode(line.strip()) for line in f]\n",
    "        for name in names:\n",
    "            try:\n",
    "                tensor_names.append(name2tensor(name))\n",
    "                target_langs.append(lang2label[lang])\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5962b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]]]),\n",
       " tensor([0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_names[2], target_langs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6432a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 52])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_names[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "909960a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(target_langs)), test_size=0.1, shuffle=True, stratify=target_langs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0806af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4406\n",
      "Test: 490\n"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(target_langs)), test_size=0.1, shuffle=True, stratify=target_langs\n",
    ")\n",
    "\n",
    "train_dataset = [(tensor_names[i], target_langs[i]) for i in train_idx]\n",
    "\n",
    "test_dataset = [(tensor_names[i], target_langs[i]) for i in test_idx]\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efd7f8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 52])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1cc7a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 180])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.zeros(1, 52), torch.zeros(1, 128)), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d90fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "    ):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_2_hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_2_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.hidden_2_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input,\n",
    "        hidden,\n",
    "    ):\n",
    "        hidden = F.tanh(self.input_2_hidden(input) + self.hidden_2_hidden(hidden))\n",
    "        output = self.hidden_2_output(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(\n",
    "        self,\n",
    "    ):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1810141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "learning_rate = 0.0001 # 1e-3\n",
    "\n",
    "model = MyRNN(num_letters, hidden_size, num_langs).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef4df52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [500/4406], Loss: 2.1679\n",
      "Epoch [1/5], Step [1000/4406], Loss: 2.2954\n",
      "Epoch [1/5], Step [1500/4406], Loss: 0.9446\n",
      "Epoch [1/5], Step [2000/4406], Loss: 0.2101\n",
      "Epoch [1/5], Step [2500/4406], Loss: 0.4039\n",
      "Epoch [1/5], Step [3000/4406], Loss: 0.2436\n",
      "Epoch [1/5], Step [3500/4406], Loss: 0.0430\n",
      "Epoch [1/5], Step [4000/4406], Loss: 2.1790\n",
      "Epoch [2/5], Step [500/4406], Loss: 1.1256\n",
      "Epoch [2/5], Step [1000/4406], Loss: 0.4066\n",
      "Epoch [2/5], Step [1500/4406], Loss: 0.0866\n",
      "Epoch [2/5], Step [2000/4406], Loss: 2.0380\n",
      "Epoch [2/5], Step [2500/4406], Loss: 0.4662\n",
      "Epoch [2/5], Step [3000/4406], Loss: 2.5327\n",
      "Epoch [2/5], Step [3500/4406], Loss: 0.1123\n",
      "Epoch [2/5], Step [4000/4406], Loss: 0.3766\n",
      "Epoch [3/5], Step [500/4406], Loss: 1.6536\n",
      "Epoch [3/5], Step [1000/4406], Loss: 2.9541\n",
      "Epoch [3/5], Step [1500/4406], Loss: 2.8093\n",
      "Epoch [3/5], Step [2000/4406], Loss: 0.6116\n",
      "Epoch [3/5], Step [2500/4406], Loss: 1.0921\n",
      "Epoch [3/5], Step [3000/4406], Loss: 1.6476\n",
      "Epoch [3/5], Step [3500/4406], Loss: 1.2964\n",
      "Epoch [3/5], Step [4000/4406], Loss: 2.2479\n",
      "Epoch [4/5], Step [500/4406], Loss: 2.2727\n",
      "Epoch [4/5], Step [1000/4406], Loss: 0.2931\n",
      "Epoch [4/5], Step [1500/4406], Loss: 0.7478\n",
      "Epoch [4/5], Step [2000/4406], Loss: 0.2136\n",
      "Epoch [4/5], Step [2500/4406], Loss: 1.0594\n",
      "Epoch [4/5], Step [3000/4406], Loss: 1.9585\n",
      "Epoch [4/5], Step [3500/4406], Loss: 0.6909\n",
      "Epoch [4/5], Step [4000/4406], Loss: 2.5359\n",
      "Epoch [5/5], Step [500/4406], Loss: 0.0212\n",
      "Epoch [5/5], Step [1000/4406], Loss: 3.1153\n",
      "Epoch [5/5], Step [1500/4406], Loss: 0.1070\n",
      "Epoch [5/5], Step [2000/4406], Loss: 0.5726\n",
      "Epoch [5/5], Step [2500/4406], Loss: 5.3170\n",
      "Epoch [5/5], Step [3000/4406], Loss: 1.8249\n",
      "Epoch [5/5], Step [3500/4406], Loss: 1.7662\n",
      "Epoch [5/5], Step [4000/4406], Loss: 1.6501\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "print_interval = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(train_dataset)\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        hidden_state = model.init_hidden()\n",
    "        hidden_state = hidden_state.to(DEVICE)\n",
    "        name = name.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        for char in name:\n",
    "            #char dim = 1x52\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "044a4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.1633%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        hidden_state = model.init_hidden()\n",
    "        hidden_state = hidden_state.to(DEVICE)\n",
    "        name = name.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += bool(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00e86226",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2lang = {label.item(): lang for lang, label in lang2label.items()}\n",
    "\n",
    "\n",
    "def myrnn_predict(name):\n",
    "    model.eval()\n",
    "    tensor_name = name2tensor(name)\n",
    "    with torch.no_grad():\n",
    "        hidden_state = model.init_hidden()\n",
    "        hidden_state = hidden_state.to(DEVICE)\n",
    "        tensor_name = tensor_name.to(DEVICE)\n",
    "        for char in tensor_name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "    model.train()\n",
    "    return label2lang[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c69f7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrnn_predict(\"Federico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f5c3d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrnn_predict(\"Xin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf12347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrnn_predict(\"Iskander\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3126e8d",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit Neural Networks\n",
    "\n",
    "A Gated Recurrent Unit (GRU), as its name suggests, is a variant of the RNN architecture, and uses gating mechanisms to control and manage the flow of information between cells in the neural network. GRUs were introduced only in 2014 by Cho, et al. and can be considered a relatively new architecture, especially when compared to the widely-adopted LSTM, which was proposed in 1997 by Sepp Hochreiter and Jürgen Schmidhuber.\n",
    "\n",
    "![alt text](https://blog.floydhub.com/content/images/2019/07/image17-1.jpg)\n",
    "\n",
    "The structure of the GRU allows it to adaptively capture dependencies from large sequences of data without discarding information from earlier parts of the sequence. This is achieved through its gating units, similar to the ones in LSTMs, which solve the vanishing/exploding gradient problem of traditional RNNs. These gates are responsible for regulating the information to be kept or discarded at each time step.\n",
    "\n",
    "![alt text](https://blog.floydhub.com/content/images/2019/07/image15.jpg)\n",
    "\n",
    "Other than its internal gating mechanisms, the GRU functions just like an RNN, where sequential input data is consumed by the GRU cell at each time step along with the memory, or otherwise known as the hidden state. The hidden state is then re-fed into the RNN cell together with the next input data in the sequence. This process continues like a relay system, producing the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c17b5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=num_letters,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_langs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_state = self.init_hidden()\n",
    "        output, hidden_state = self.gru(x, hidden_state)\n",
    "        output = self.fc(output[-1])\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "367d15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(num_layers=2, hidden_size=hidden_size).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2a607d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [500/4406], Loss: 2.5898\n",
      "Epoch [1/4], Step [1000/4406], Loss: 1.5315\n",
      "Epoch [1/4], Step [1500/4406], Loss: 2.1059\n",
      "Epoch [1/4], Step [2000/4406], Loss: 2.8973\n",
      "Epoch [1/4], Step [2500/4406], Loss: 2.0770\n",
      "Epoch [1/4], Step [3000/4406], Loss: 0.0929\n",
      "Epoch [1/4], Step [3500/4406], Loss: 2.9198\n",
      "Epoch [1/4], Step [4000/4406], Loss: 2.8344\n",
      "Epoch [2/4], Step [500/4406], Loss: 0.5632\n",
      "Epoch [2/4], Step [1000/4406], Loss: 2.2569\n",
      "Epoch [2/4], Step [1500/4406], Loss: 0.4495\n",
      "Epoch [2/4], Step [2000/4406], Loss: 0.0000\n",
      "Epoch [2/4], Step [2500/4406], Loss: 3.2544\n",
      "Epoch [2/4], Step [3000/4406], Loss: 3.5822\n",
      "Epoch [2/4], Step [3500/4406], Loss: 0.0046\n",
      "Epoch [2/4], Step [4000/4406], Loss: 1.8146\n",
      "Epoch [3/4], Step [500/4406], Loss: 0.0170\n",
      "Epoch [3/4], Step [1000/4406], Loss: 0.0470\n",
      "Epoch [3/4], Step [1500/4406], Loss: 0.2245\n",
      "Epoch [3/4], Step [2000/4406], Loss: 0.4016\n",
      "Epoch [3/4], Step [2500/4406], Loss: 2.5534\n",
      "Epoch [3/4], Step [3000/4406], Loss: 0.0472\n",
      "Epoch [3/4], Step [3500/4406], Loss: 0.6971\n",
      "Epoch [3/4], Step [4000/4406], Loss: 2.1994\n",
      "Epoch [4/4], Step [500/4406], Loss: 0.5324\n",
      "Epoch [4/4], Step [1000/4406], Loss: 6.0766\n",
      "Epoch [4/4], Step [1500/4406], Loss: 1.6490\n",
      "Epoch [4/4], Step [2000/4406], Loss: 3.2461\n",
      "Epoch [4/4], Step [2500/4406], Loss: 2.7378\n",
      "Epoch [4/4], Step [3000/4406], Loss: 0.0000\n",
      "Epoch [4/4], Step [3500/4406], Loss: 2.5679\n",
      "Epoch [4/4], Step [4000/4406], Loss: 0.0388\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(train_dataset)\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        name = name.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        output = model(name)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "baf9cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.1633%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, label in test_dataset:\n",
    "        name = name.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        output = model(name)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += bool(pred == label)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2342fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_predict(name):\n",
    "    model.eval()\n",
    "    tensor_name = name2tensor(name)\n",
    "    with torch.no_grad():\n",
    "        tensor_name = tensor_name.to(DEVICE)\n",
    "        output = model(tensor_name)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "    model.train()\n",
    "    return label2lang[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05d6e084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Czech'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predict(\"Jake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3de988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predict(\"Qin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76065b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predict(\"Fernando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f9efc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russian'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predict(\"Demirkan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0580ed",
   "metadata": {},
   "source": [
    "GRU -> https://blog.floydhub.com/gru-with-pytorch/\n",
    "LSTM -> https://cnvrg.io/pytorch-lstm/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cme-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
